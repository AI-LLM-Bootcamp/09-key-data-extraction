{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Key Data Extraction App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* We will create an app to **extract structured information from unstructured text**. Imagine, for example, that you want to extract the name, the lastname and the country of the users that submit comments in the website of your company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 001-key-data-extraction.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4d328-bec5-4daf-a4f5-186c03762fed",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **001-key-data-extraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d02e49-5d84-4947-8419-4fec37b0c05f",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e9a38-0e0c-4835-ac05-f87ba7f8b823",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f4ab2c-fd5a-4c6e-947e-83dea4cb73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "## Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10da0f-603c-4bd9-8b9f-2f6dbf96b6e0",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a17c7-26cd-446b-9c82-f3fb94dcdaed",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba89426-c952-43a3-aa6c-a7430d7aa8c1",
   "metadata": {},
   "source": [
    "## Define what information you want to extract\n",
    "* **We'll use Pydantic to define an schema to extract personal information**.\n",
    "* Pydantic is a Python library used for data validation. It helps ensure that the data your program receives matches the format you expect, and it provides helpful error messages when the data doesn't conform to your specifications. Essentially, Pydantic allows you to enforce that the data structures in Python adhere to specific types and constraints, making your code more robust and error-resistant.\n",
    "* **Document the attributes and the schema itself**: This information is sent to the LLM and is used to improve the quality of information extraction.\n",
    "* Do not force the LLM to make up information! **We import Optional for the attributes allowing the LLM to output None if it doesn't know the answer**.\n",
    "* When you use Optional in type hints, you are indicating that a variable can either be of a specified type or it can be None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa25289-7fa7-468b-a981-495da9bb4a5d",
   "metadata": {},
   "source": [
    "#### Let's define the data we want to extract from a person.\n",
    "* See below that it is a good practice to write an explanatory doc-string (comments) to help the chat model understanding what data we want to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b3d81a-e4d3-4956-807b-1ab147146390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(\n",
    "        default=None, description=\"The name of the person\"\n",
    "    )\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"The lastname of the person if known\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"The country of the person if known\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219dde9c-3139-442c-a3be-1b9185f7a644",
   "metadata": {},
   "source": [
    "## Define the Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301c8fb-c905-4cd2-aa04-68eb7399ecf3",
   "metadata": {},
   "source": [
    "Our extractor will be a chain with the prompt template and a chat model with the extraction instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab077d5b-d86c-4d0e-baac-b19cbe6ace83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) You can introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c14b0-976b-4340-bcb3-46109584d987",
   "metadata": {},
   "source": [
    "* We need to use a model that supports function/tool calling.\n",
    "* Please review [the documentation](https://python.langchain.com/v0.2/docs/concepts/#function-tool-calling) for list of some models that can be used with this API.\n",
    "* **We will use .with_structured_output() to add the extraction instructions to our chat model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb3cd0d-fc9a-4223-a1ef-5857dc0e4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05698c54-da74-4ff5-b7ff-d9bb22d6f726",
   "metadata": {},
   "source": [
    "## Try the extraction app\n",
    "See how the app extracts the name, lastname and country form one user review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082c7c53-0a94-4a59-b5a7-d3a186402467",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I absolutely love this product! It's been a game-changer for my daily routine. The quality is top-notch and the customer service is outstanding. I've recommended it to all my friends and family. - Sarah Johnson, USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39cb512c-5b2e-4aeb-9821-6395809a8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Sarah', lastname='Johnson', country='USA')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05023e96-9c9b-4102-b902-7e244b78ee6f",
   "metadata": {},
   "source": [
    "* **Note that this extraction capability is generative**, which means that our model can perform a variety of tasks beyond the expected. For instance, the model could infer the gender of a user from their name, even when this information is not explicitly provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14033470-3abb-4cc5-ad4c-da9370e0a6d6",
   "metadata": {},
   "source": [
    "## Extraction of a list of entities rather than a single entity\n",
    "* In real projects you will probably work with a large text that includes more than one user review. **We can extract the key data of several users by nesting Pydantic models**.\n",
    "* See how the Data model definition is including the Person model. This is technically called \"nesting\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40267cdd-9e8c-4ca8-b90f-4197b99f3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(\n",
    "        default=None, description=\"The name of the person\"\n",
    "    )\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"The lastname of the person if known\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"The country of the person if known\"\n",
    "    )\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7155b07-79e9-4495-b832-447ed255b88c",
   "metadata": {},
   "source": [
    "See how now we are using the Data model with the llm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4572231-c88c-474f-8421-788ed4f1115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39646a67-a02c-4e80-a2ad-3ea2cf6b8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I'm so impressed with this product! It has truly transformed how I approach my daily tasks. The quality exceeds my expectations, and the customer support is truly exceptional. I've already suggested it to all my colleagues and relatives. - Emily Clarke, Canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffbad47-807a-4607-b4e1-e6b472b2c9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Emily', lastname='Clarke', country='Canada')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696aba01-c18a-4190-99fa-a8eaed089729",
   "metadata": {},
   "source": [
    "#### Let's now see this at work with a text with several reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e128d1fe-54d1-4c9f-893c-a93b831a8df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Alice', lastname='Johnson', country='Canada'), Person(name='Bob', lastname='Smith', country='USA')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example input text that mentions multiple people\n",
    "text_input = \"\"\"\n",
    "Alice Johnson from Canada recently reviewed a book she loved. Meanwhile, Bob Smith from the USA shared his insights on the same book in a different review. Both reviews were very insightful.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke the processing chain on the text\n",
    "response = chain.invoke({\"text\": text_input})\n",
    "\n",
    "# Output the extracted data\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b64c08-13cc-4f1d-a4d7-28c2925c1c4c",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-key-data-extraction.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-key-data-extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0613532-68c1-4de2-b143-5cd71f7ce28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
